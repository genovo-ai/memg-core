MEMG Core Test Failures - Need Test Author to Fix
================================================

STATUS: 10 tests failing, all search-related. Core logic works (73 tests pass).

PROBLEM: graph_rag_search() consistently returns empty results when it should find data.

ROOT CAUSE ANALYSIS:
1. FakeQdrant.search_points() user_id filtering logic may be broken
2. Payload structure mismatch between what tests store vs what search expects
3. Graph query logic in FakeKuzu may not match real behavior

FAILING TESTS:
- tests/pipeline/test_retrieval.py (3 failures)
- tests/edge_cases/test_edge_cases.py (3 failures)
- tests/e2e/test_real_fastembed.py (2 failures)
- tests/integration/test_integration.py (2 failures)

KEY ISSUE: All tests that call graph_rag_search() get [] instead of expected results.

ACTION NEEDED: Fix fake storage adapters in tests/conftest.py or test data setup.

SUSPECTS:
- FakeQdrant.search_points() filtering
- FakeKuzu.query() return format
- Memory payload structure in test setup

========================================
RELATED FILES FOR DEBUGGING
========================================

=== CORE: graph_rag_search() function ===
# memg_core/core/pipeline/retrieval.py
"""Unified retrieval pipeline with automatic mode selection and neighbor expansion.
- Anchor-first: uses `statement` as the only textual anchor.
- Modes: vector-first (Qdrant), graph-first (Kuzu), hybrid (merge).
- Filters: user_id, memo_type, modified_within_days, arbitrary filters.
- Deterministic ordering: score DESC, then hrid index ASC, then id ASC.
"""

from __future__ import annotations

from datetime import UTC, datetime, timedelta
from typing import Any
from uuid import uuid4

from ...utils.hrid import hrid_to_index  # NEW
from ..exceptions import DatabaseError
from ..interfaces.embedder import Embedder
from ..interfaces.kuzu import KuzuInterface
from ..interfaces.qdrant import QdrantInterface
from ..models import Memory, SearchResult

# ----------------------------- helpers ---------------------------------


# NEW: deterministic field projection for payloads
def _project_payload(
    memory_type: str,
    payload: dict[str, Any] | None,
    *,
    include_details: str,
    projection: dict[str, list[str]] | None,
) -> dict[str, Any]:
    """
    Returns a pruned payload based on include_details and optional projection mapping.

    Policy (v1):
      - include_details="none": anchors only → keep just "statement" if present.
      - include_details="self": anchors + optional projection for anchors; always keep "statement" if present.
      - include_details other values are reserved for future; treated like "self".
      - Neighbors remain anchors-only regardless (we don't hydrate neighbor details in v1).
    """
    payload = dict(payload or {})
    if not payload:
        return {}

    # Always prefer having "statement" present if it exists
    has_stmt = "statement" in payload

    if include_details == "none":
        return {"statement": payload["statement"]} if has_stmt else {}

    # self / default behavior with optional projection
    allowed: set[str] | None = None
    if projection:
        allowed = set(projection.get(memory_type, []))
        # Always include statement when present
        if has_stmt:
            allowed.add("statement")

    if allowed is None:
        # No projection → return as-is
        return payload

    # With projection → prune to allowed keys
    return {k: v for k, v in payload.items() if k in allowed}


def _now() -> datetime:
    return datetime.now(UTC)


def _iso(dt: datetime | None) -> str:
    return (dt or _now()).isoformat()


def _cutoff(days: int | None) -> datetime | None:
    if days is None or days <= 0:
        return None
    return _now() - timedelta(days=days)


def _parse_datetime(date_str: Any) -> datetime:
    if isinstance(date_str, str):
        try:
            return datetime.fromisoformat(date_str)
        except (ValueError, TypeError):
            return _now()
    return _now()


def _sort_key(r: SearchResult) -> tuple:
    """Stable ordering: score DESC, then hrid index ASC, then id ASC."""
    mem = r.memory
    try:
        idx = hrid_to_index(getattr(mem, "hrid", "") or "ZZZ_ZZZ999")
    except Exception:
        idx = 26**3 * 1000 + 999  # worst case
    return (-float(r.score or 0.0), idx, mem.id or "")


# ----------------------------- Kuzu ------------------------------------


def _build_graph_query_for_memos(
    query: str | None,
    *,
    user_id: str | None,
    limit: int,
    relation_names: list[str] | None = None,
    memo_type: str | None = None,
    modified_within_days: int | None = None,
) -> tuple[str, dict[str, Any]]:
    """Graph-first: fetch Memo nodes by filters (no Entity matching).
    Returns m.* fields only; neighbors will be fetched separately.
    """
    params: dict[str, Any] = {"limit": limit}

    cypher = "MATCH (m:Memory)\nWHERE 1=1"
    if user_id:
        cypher += " AND m.user_id = $user_id"
        params["user_id"] = user_id
    if memo_type:
        cypher += " AND m.memory_type = $memo_type"
        params["memo_type"] = memo_type
    cut = _cutoff(modified_within_days)
    if cut is not None:
        cypher += " AND m.created_at >= $cutoff"
        params["cutoff"] = _iso(cut)

    cypher += (
        "\nRETURN DISTINCT "
        "m.id, m.user_id, m.memory_type, m.hrid, m.statement, m.tags, m.created_at, m.updated_at\n"
        "ORDER BY coalesce(m.updated_at, m.created_at) DESC\n"
        "LIMIT $limit"
    )
    return cypher, params


def _rows_to_memories(rows: list[dict[str, Any]]) -> list[Memory]:
    out: list[Memory] = []
    for row in rows:
        mtype = row.get("m.memory_type") or row.get("memory_type") or "memo"
        statement = row.get("m.statement") or row.get("statement") or ""
        created_at_raw = row.get("m.created_at") or row.get("created_at")
        # updated_at_raw = row.get("m.updated_at") or row.get("updated_at")
        tags_raw = row.get("m.tags") or row.get("tags") or []
        hrid = row.get("m.hrid") or row.get("hrid")  # NEW

        if isinstance(tags_raw, str):
            tags = [t for t in tags_raw.split(",") if t]
        else:
            tags = list(tags_raw)

        # Build payload from available row fields
        payload = {"statement": statement}

        # Include other available fields in payload
        title = row.get("m.title") or row.get("title")
        if title:
            payload["title"] = title

        summary = row.get("m.summary") or row.get("summary")
        if summary:
            payload["summary"] = summary

        task_status = row.get("m.task_status") or row.get("task_status")
        if task_status:
            payload["task_status"] = task_status

        assignee = row.get("m.assignee") or row.get("assignee")
        if assignee:
            payload["assignee"] = assignee

        out.append(
            Memory(
                id=row.get("m.id") or row.get("id") or str(uuid4()),
                user_id=row.get("m.user_id") or row.get("user_id", ""),
                memory_type=mtype,
                payload=payload,
                tags=tags,
                confidence=0.8,
                is_valid=True,
                created_at=_parse_datetime(created_at_raw),
                supersedes=None,
                superseded_by=None,
                vector=None,
                hrid=hrid,
            )
        )
    return out


# ----------------------------- Qdrant ----------------------------------


def _qdrant_filters(
    user_id: str | None,
    memo_type: str | None,
    modified_within_days: int | None,
    extra: dict[str, Any] | None,
) -> dict[str, Any]:
    f: dict[str, Any] = extra.copy() if extra else {}
    if user_id:
        f["core.user_id"] = user_id
    if memo_type:
        f["core.memory_type"] = memo_type
    cut = _cutoff(modified_within_days)
    if cut is not None:
        f["core.updated_at_from"] = _iso(cut)  # adapter layer should translate to a proper Range
    return f


# ----------------------------- Rerank/Neighbors ------------------------


def _rerank_with_vectors(
    query: str, candidates: list[Memory], qdrant: QdrantInterface, embedder: Embedder
) -> list[SearchResult]:
    qvec = embedder.get_embedding(query)
    vec_results = qdrant.search_points(vector=qvec, limit=max(10, len(candidates)))
    score_by_id = {r.get("id"): float(r.get("score", 0.0)) for r in vec_results}

    results: list[SearchResult] = []
    for mem in candidates:
        score = score_by_id.get(mem.id, 0.5)
        results.append(
            SearchResult(memory=mem, score=score, distance=None, source="graph_rerank", metadata={})
        )
    results.sort(key=_sort_key)
    return results


def _append_neighbors(
    seeds: list[SearchResult],
    kuzu: KuzuInterface,
    neighbor_limit: int,
    relation_names: list[str] | None,
) -> list[SearchResult]:
    expanded: list[SearchResult] = []
    # NEW: default whitelist used if none provided (anchors-only neighbors)
    rels = relation_names or ["RELATED_TO", "HAS_DOCUMENT", "REQUIRES"]

    for seed in seeds[: min(5, len(seeds))]:
        mem = seed.memory
        if not mem.id:
            continue
        rows = kuzu.neighbors(
            node_label="Memory",
            node_id=mem.id,
            rel_types=rels,
            direction="any",
            limit=neighbor_limit,
            neighbor_label="Memory",
        )
        for row in rows:
            statement = row.get("statement", "")
            neighbor = Memory(
                id=row.get("id") or str(uuid4()),
                user_id=row.get("user_id", ""),
                memory_type=row.get("memory_type", "memo"),
                payload={"statement": statement},
                confidence=0.8,
                is_valid=True,
                created_at=_parse_datetime(row.get("created_at")),
                supersedes=None,
                superseded_by=None,
                vector=None,
                tags=[],
                hrid=row.get("hrid"),  # NEW: if present
            )
            expanded.append(
                SearchResult(
                    memory=neighbor,
                    score=max(0.3, seed.score * 0.9),
                    distance=None,
                    source="graph_neighbor",
                    metadata={"from": mem.id},
                )
            )

    # merge by id keep max score
    by_id: dict[str, SearchResult] = {r.memory.id: r for r in seeds}
    for r in expanded:
        cur = by_id.get(r.memory.id)
        if cur is None or r.score > cur.score:
            by_id[r.memory.id] = r
    out = list(by_id.values())
    out.sort(key=_sort_key)
    return out


# ----------------------------- Entry Point -----------------------------


def graph_rag_search(
    query: str | None,
    user_id: str,
    limit: int,
    qdrant: QdrantInterface,
    kuzu: KuzuInterface,
    embedder: Embedder,
    filters: dict[str, Any] | None = None,
    relation_names: list[str] | None = None,
    neighbor_cap: int = 5,
    *,
    memo_type: str | None = None,
    modified_within_days: int | None = None,
    mode: str | None = None,  # 'vector' | 'graph' | 'hybrid'
    include_details: str = "none",  # NEW: "none" | "self" (neighbors remain anchors-only in v1)
    projection: dict[str, list[str]] | None = None,  # NEW: per-type field allow-list
) -> list[SearchResult]:
    """Unified retrieval with automatic mode selection.

    - If `query` is provided → vector-first.
    - If no `query` but `memo_type/filters/date` are provided → graph-first.
    - If both and `mode='hybrid'` → merge by id with stable ordering.
    """
    # ---------------- validation ----------------
    has_query = bool(query and query.strip())
    has_scope = bool(memo_type or (filters and len(filters) > 0) or modified_within_days)
    if not has_query and not has_scope:
        return []

    # decide mode
    eff_mode = mode or ("vector" if has_query else "graph")

    results: list[SearchResult] = []

    try:
        if eff_mode == "graph":
            cypher, params = _build_graph_query_for_memos(
                query,
                user_id=user_id,
                limit=limit,
                relation_names=relation_names,
                memo_type=memo_type,
                modified_within_days=modified_within_days,
            )
            rows = kuzu.query(cypher, params)
            candidates = _rows_to_memories(rows)
            if has_query and candidates:
                results = _rerank_with_vectors(query or "", candidates, qdrant, embedder)
            else:
                # score-less anchors with projection
                proj = []
                for m in candidates:
                    m.payload = _project_payload(
                        m.memory_type,
                        m.payload,
                        include_details=include_details,
                        projection=projection,
                    )
                    proj.append(
                        SearchResult(
                            memory=m, score=0.5, distance=None, source="graph", metadata={}
                        )
                    )
                results = proj
        elif eff_mode == "vector":
            qf = _qdrant_filters(user_id, memo_type, modified_within_days, filters)
            qvec = embedder.get_embedding(query or "")
            vec = qdrant.search_points(vector=qvec, limit=limit, user_id=user_id, filters=qf)
            for r in vec:
                payload = r.get("payload", {})
                core = payload.get("core", {})
                entity = payload.get("entity", {})
                statement = entity.get("statement") or core.get("statement") or ""
                m = Memory(
                    id=r.get("id") or str(uuid4()),
                    user_id=core.get("user_id", ""),
                    memory_type=core.get("memory_type", "memo"),
                    payload={
                        "statement": statement,
                        **{k: v for k, v in entity.items() if k != "statement"},
                    },
                    tags=core.get("tags", []),
                    confidence=core.get("confidence", 0.8),
                    is_valid=core.get("is_valid", True),
                    created_at=_parse_datetime(core.get("created_at")),
                    supersedes=core.get("supersedes"),
                    superseded_by=core.get("superseded_by"),
                    vector=None,
                    hrid=core.get("hrid"),  # NEW
                )
                # NEW: project anchor payload according to include_details/projection
                m.payload = _project_payload(
                    m.memory_type, m.payload, include_details=include_details, projection=projection
                )
                results.append(
                    SearchResult(
                        memory=m,
                        score=float(r.get("score", 0.0)),
                        distance=None,
                        source="qdrant",
                        metadata={},
                    )
                )
        else:  # hybrid
            cypher, params = _build_graph_query_for_memos(
                query,
                user_id=user_id,
                limit=limit,
                relation_names=relation_names,
                memo_type=memo_type,
                modified_within_days=modified_within_days,
            )
            rows = kuzu.query(cypher, params)
            candidates = _rows_to_memories(rows)
            qf = _qdrant_filters(user_id, memo_type, modified_within_days, filters)
            qvec = embedder.get_embedding(query or "")
            vec = qdrant.search_points(vector=qvec, limit=limit, user_id=user_id, filters=qf)

            vec_mems: list[SearchResult] = []
            for r in vec:
                payload = r.get("payload", {})
                core = payload.get("core", {})
                entity = payload.get("entity", {})
                statement = entity.get("statement") or core.get("statement") or ""
                m = Memory(
                    id=r.get("id") or str(uuid4()),
                    user_id=core.get("user_id", ""),
                    memory_type=core.get("memory_type", "memo"),
                    payload={
                        "statement": statement,
                        **{k: v for k, v in entity.items() if k != "statement"},
                    },
                    tags=core.get("tags", []),
                    confidence=core.get("confidence", 0.8),
                    is_valid=core.get("is_valid", True),
                    created_at=_parse_datetime(core.get("created_at")),
                    supersedes=core.get("supersedes"),
                    superseded_by=core.get("superseded_by"),
                    vector=None,
                    hrid=core.get("hrid"),  # NEW
                )
                m.payload = _project_payload(
                    m.memory_type, m.payload, include_details=include_details, projection=projection
                )
                vec_mems.append(
                    SearchResult(
                        memory=m,
                        score=float(r.get("score", 0.0)),
                        distance=None,
                        source="qdrant",
                        metadata={},
                    )
                )

            by_id: dict[str, SearchResult] = {r.memory.id: r for r in vec_mems}
            for m in candidates:
                m.payload = _project_payload(
                    m.memory_type, m.payload, include_details=include_details, projection=projection
                )
                sr = by_id.get(m.id)
                if sr is None or sr.score < 0.5:
                    by_id[m.id] = SearchResult(
                        memory=m, score=0.5, distance=None, source="graph", metadata={}
                    )
            results = list(by_id.values())

    except DatabaseError:
        if has_query:
            qf = _qdrant_filters(user_id, memo_type, modified_within_days, filters)
            qvec = embedder.get_embedding(query or "")
            vec = qdrant.search_points(vector=qvec, limit=limit, user_id=user_id, filters=qf)
            for r in vec:
                payload = r.get("payload", {})
                core = payload.get("core", {})
                entity = payload.get("entity", {})
                statement = entity.get("statement") or core.get("statement") or ""
                m = Memory(
                    id=r.get("id") or str(uuid4()),
                    user_id=core.get("user_id", ""),
                    memory_type=core.get("memory_type", "memo"),
                    payload={
                        "statement": statement,
                        **{k: v for k, v in entity.items() if k != "statement"},
                    },
                    tags=core.get("tags", []),
                    confidence=core.get("confidence", 0.8),
                    is_valid=core.get("is_valid", True),
                    created_at=_parse_datetime(core.get("created_at")),
                    supersedes=core.get("supersedes"),
                    superseded_by=core.get("superseded_by"),
                    vector=None,
                    hrid=core.get("hrid"),  # NEW
                )
                # NEW: project anchor payload according to include_details/projection
                m.payload = _project_payload(
                    m.memory_type, m.payload, include_details=include_details, projection=projection
                )
                results.append(
                    SearchResult(
                        memory=m,
                        score=float(r.get("score", 0.0)),
                        distance=None,
                        source="qdrant",
                        metadata={},
                    )
                )
        else:
            results = []

    # neighbors (anchors only)
    results = _append_neighbors(results, kuzu, neighbor_cap, relation_names)

    # final order & clamp
    def _sort_key(r: SearchResult):
        h = r.memory.hrid
        h_idx = hrid_to_index(h) if h else 9_999_999_999  # push missing HRIDs last
        return (-r.score, h_idx, r.memory.id)

    results.sort(key=_sort_key)
    return results[:limit]

=== TEST: Fake storage adapters ===
"""Test fixtures and test doubles for memg_core tests."""

import hashlib
import json
import os
from datetime import UTC, datetime
from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union
from uuid import uuid4

import pytest
from pydantic import BaseModel

from memg_core.core.interfaces.embedder import Embedder
from memg_core.core.interfaces.kuzu import KuzuInterface
from memg_core.core.interfaces.qdrant import QdrantInterface
from memg_core.core.models import Memory


class DummyEmbedder:
    """Test double for Embedder that returns deterministic vectors."""

    def __init__(self, vector_size: int = 384):
        """Initialize with configurable vector size."""
        self.vector_size = vector_size
        # Skip parent initialization to avoid API key requirements

    def get_embedding(self, text: str) -> List[float]:
        """Generate a deterministic vector based on text hash."""
        # Create a hash of the input text
        text_hash = hashlib.md5(text.encode()).hexdigest()

        # Convert hash to a list of floats between -1 and 1
        hash_bytes = bytes.fromhex(text_hash)
        vector = []
        for i in range(self.vector_size):
            # Use modulo to cycle through the hash bytes
            byte_val = hash_bytes[i % len(hash_bytes)]
            # Convert to float between -1 and 1
            vector.append((byte_val / 128.0) - 1.0)

        return vector


class FakeQdrant(QdrantInterface):
    """Test double for QdrantInterface with in-memory storage."""

    def __init__(self, collection_name: str = "memories"):
        """Initialize with in-memory storage."""
        self.collection_name = collection_name
        self.collections: Dict[str, Dict[str, Dict]] = {}
        self.points: Dict[str, Dict[str, Any]] = {}  # collection_name -> {id: {vector, payload}}

    def collection_exists(self, collection: Optional[str] = None) -> bool:
        """Check if collection exists."""
        collection = collection or self.collection_name
        return collection in self.collections

    def create_collection(self, collection: Optional[str] = None, vector_size: int = 384) -> bool:
        """Create a new collection."""
        collection = collection or self.collection_name
        if collection not in self.collections:
            self.collections[collection] = {}
            self.points[collection] = {}
        return True

    def ensure_collection(self, collection: Optional[str] = None, vector_size: int = 384) -> bool:
        """Ensure collection exists, create if it doesn't."""
        collection = collection or self.collection_name
        if collection not in self.collections:
            return self.create_collection(collection, vector_size)
        return True

    def add_point(
        self,
        vector: List[float],
        payload: Dict[str, Any],
        point_id: Optional[str] = None,
        collection: Optional[str] = None,
    ) -> Tuple[bool, str]:
        """Add a single point to collection."""
        collection = collection or self.collection_name
        self.ensure_collection(collection)

        if point_id is None:
            point_id = str(uuid4())
        elif not isinstance(point_id, str):
            point_id = str(point_id)

        self.points[collection][point_id] = {
            "vector": vector,
            "payload": payload,
        }
        return True, point_id

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """Calculate cosine similarity between two vectors."""
        if len(vec1) != len(vec2):
            # Handle different vector sizes by padding the shorter one
            if len(vec1) < len(vec2):
                vec1 = vec1 + [0.0] * (len(vec2) - len(vec1))
            else:
                vec2 = vec2 + [0.0] * (len(vec1) - len(vec2))

        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm_a = sum(a * a for a in vec1) ** 0.5
        norm_b = sum(b * b for b in vec2) ** 0.5

        if norm_a == 0 or norm_b == 0:
            return 0.0

        return dot_product / (norm_a * norm_b)

    def search_points(
        self,
        vector: List[float],
        limit: int = 5,
        collection: Optional[str] = None,
        user_id: Optional[str] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[Dict[str, Any]]:
        """Search for similar points with optional filtering."""
        collection = collection or self.collection_name
        if collection not in self.points:
            return []

        # Calculate similarities for all points
        similarities = []
        for point_id, point_data in self.points[collection].items():
            # Apply filters if provided
            if filters or user_id:
                payload = point_data["payload"]

                # Apply user_id filter
                if user_id and payload.get("user_id") != user_id:
                    continue

                # Apply additional filters
                if filters:
                    skip = False
                    for key, value in filters.items():
                        if key not in payload:
                            skip = True
                            break

                        # Handle dict filters (range queries)
                        if isinstance(value, dict):
                            if "gt" in value and not (payload[key] > value["gt"]):
                                skip = True
                                break
                            if "gte" in value and not (payload[key] >= value["gte"]):
                                skip = True
                                break
                            if "lt" in value and not (payload[key] < value["lt"]):
                                skip = True
                                break
                            if "lte" in value and not (payload[key] <= value["lte"]):
                                skip = True
                                break
                        # Handle list values - check if any filter value is in the payload list
                        elif isinstance(value, list):
                            payload_value = payload[key]
                            if isinstance(payload_value, list):
                                # Check if any filter value is in the payload list
                                if not any(v in payload_value for v in value):
                                    skip = True
                                    break
                            else:
                                # Payload value is not a list, check direct membership
                                if payload_value not in value:
                                    skip = True
                                    break
                        # Handle simple equality
                        elif payload[key] != value:
                            skip = True
                            break

                    if skip:
                        continue

            # Calculate similarity and normalize to [0, 1] range
            similarity = self._cosine_similarity(vector, point_data["vector"])
            # Normalize from [-1, 1] to [0, 1]
            normalized_score = (similarity + 1.0) / 2.0
            similarities.append((point_id, normalized_score))

        # Sort by similarity (descending) and take top limit
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_similarities = similarities[:limit]

        # Format results
        results = []
        for point_id, score in top_similarities:
            point_data = self.points[collection][point_id]
            results.append({
                "id": point_id,
                "score": score,
                "payload": point_data["payload"],
            })

        return results

    def get_point(self, point_id: str, collection: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """Get a single point by ID."""
        collection = collection or self.collection_name
        if collection not in self.points or point_id not in self.points[collection]:
            return None

        point_data = self.points[collection][point_id]
        return {
            "id": point_id,
            "vector": point_data["vector"],
            "payload": point_data["payload"],
        }

    def delete_points(self, point_ids: List[str], collection: Optional[str] = None) -> bool:
        """Delete points by IDs."""
        collection = collection or self.collection_name
        if collection not in self.points:
            return True  # Nothing to delete

        for point_id in point_ids:
            if point_id in self.points[collection]:
                del self.points[collection][point_id]

        return True

    def get_collection_info(self, collection: Optional[str] = None) -> Dict[str, Any]:
        """Get collection information."""
        collection = collection or self.collection_name
        if collection not in self.collections:
            return {"exists": False}

        # Count vectors
        points_count = len(self.points.get(collection, {}))

        # Get vector size from first point if available
        vector_size = 384  # Default
        if points_count > 0:
            first_point_id = next(iter(self.points[collection]))
            vector_size = len(self.points[collection][first_point_id]["vector"])

        return {
            "exists": True,
            "vectors_count": points_count,
            "points_count": points_count,
            "config": {
                "vector_size": vector_size,
                "distance": "cosine",
            },
        }


class FakeKuzu(KuzuInterface):
    """Test double for KuzuInterface with in-memory storage."""

    def __init__(self, db_path: Optional[str] = None):
        """Initialize with in-memory storage."""
        # Skip parent initialization to avoid database requirements
        self.nodes: Dict[str, Dict[str, Dict[str, Any]]] = {
            "Memory": {},
            "Entity": {},
        }
        self.relationships: List[Dict[str, Any]] = []

    def add_node(self, table: str, properties: Dict[str, Any]) -> None:
        """Add a node to the graph."""
        if table not in self.nodes:
            self.nodes[table] = {}

        node_id = properties.get("id")
        if not node_id:
            raise ValueError("Node must have an id property")

        self.nodes[table][node_id] = properties

    def add_relationship(
        self,
        from_table: str,
        to_table: str,
        rel_type: str,
        from_id: str,
        to_id: str,
        props: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Add relationship between nodes."""
        # Validate that nodes exist
        if from_id not in self.nodes.get(from_table, {}):
            raise ValueError(f"Node {from_id} not found in table {from_table}")
        if to_id not in self.nodes.get(to_table, {}):
            raise ValueError(f"Node {to_id} not found in table {to_table}")

        # Sanitize relationship type
        rel_type = rel_type.replace(" ", "_").replace("-", "_").upper()
        rel_type = "".join(c for c in rel_type if c.isalnum() or c == "_")

        # Add relationship
        self.relationships.append({
            "from_table": from_table,
            "to_table": to_table,
            "rel_type": rel_type,
            "from_id": from_id,
            "to_id": to_id,
            "props": props or {},
        })

    def query(self, cypher: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Execute Cypher query and return results."""
        params = params or {}

        # Simple implementation that handles basic memory queries
        if "MATCH (m:Memory)" in cypher:
            # Extract user_id filter if present
            user_id = params.get("user_id")

            # Extract query text if present
            query_text = params.get("q", "").lower()

            # Extract limit
            limit = params.get("limit", 10)

            # Filter memories
            results = []
            for node_id, node in self.nodes["Memory"].items():
                # Apply user_id filter
                if user_id and node.get("user_id") != user_id:
                    continue

                # Apply text search filter
                content = node.get("content", "").lower()
                title = node.get("title", "").lower()
                if query_text and query_text not in content and query_text not in title:
                    continue

                # Add to results
                results.append({
                    "m.id": node_id,
                    "m.user_id": node.get("user_id"),
                    "m.content": node.get("content"),
                    "m.title": node.get("title"),
                    "m.memory_type": node.get("memory_type"),
                    "m.created_at": node.get("created_at"),
                    "m.summary": node.get("summary"),
                    "m.source": node.get("source"),
                    "m.tags": node.get("tags"),
                    "m.confidence": node.get("confidence"),
                })

            # Sort by created_at (descending)
            results.sort(key=lambda x: x.get("m.created_at", ""), reverse=True)

            # Apply limit
            return results[:limit]

        # Return empty list for unsupported queries
        return []

    def neighbors(
        self,
        node_label: str,
        node_id: str,
        rel_types: Optional[List[str]] = None,
        direction: str = "any",
        limit: int = 10,
        neighbor_label: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """Fetch neighbors of a node."""
        results = []

        # Find relationships involving the node
        for rel in self.relationships:
            rel_type = rel["rel_type"]

            # Filter by relation type if specified
            if rel_types and rel_type not in rel_types:
                continue

            # Check direction and node label
            is_outgoing = (rel["from_table"] == node_label and rel["from_id"] == node_id)
            is_incoming = (rel["to_table"] == node_label and rel["to_id"] == node_id)

            if (direction == "out" and is_outgoing) or (direction == "in" and is_incoming) or (direction == "any" and (is_outgoing or is_incoming)):
                # Determine the neighbor node
                if is_outgoing:
                    neighbor_table = rel["to_table"]
                    neighbor_id = rel["to_id"]
                else:
                    neighbor_table = rel["from_table"]
                    neighbor_id = rel["from_id"]

                # Filter by neighbor label if specified
                if neighbor_label and neighbor_table != neighbor_label:
                    continue

                # Get the neighbor node
                if neighbor_id in self.nodes.get(neighbor_table, {}):
                    neighbor = self.nodes[neighbor_table][neighbor_id]

                    # Format result based on neighbor type
                    if neighbor_table == "Memory":
                        results.append({
                            "id": neighbor_id,
                            "user_id": neighbor.get("user_id"),
                            "content": neighbor.get("content"),
                            "title": neighbor.get("title"),
                            "memory_type": neighbor.get("memory_type"),
                            "created_at": neighbor.get("created_at"),
                            "rel_type": rel_type,
                        })
                    else:
                        results.append({
                            "node": neighbor,
                            "rel_type": rel_type,
                        })

        # Apply limit
        return results[:limit]


@pytest.fixture
def embedder() -> DummyEmbedder:
    """Fixture for DummyEmbedder."""
    return DummyEmbedder()


@pytest.fixture
def qdrant_fake() -> FakeQdrant:
    """Fixture for FakeQdrant."""
    return FakeQdrant()


@pytest.fixture
def kuzu_fake() -> FakeKuzu:
    """Fixture for FakeKuzu."""
    return FakeKuzu()


@pytest.fixture
def mem_factory() -> Callable[..., Memory]:
    """Fixture for creating Memory objects with defaults."""
    def _create_memory(**kwargs) -> Memory:
        defaults = {
            "id": str(uuid4()),
            "user_id": "test-user",
            "memory_type": "note",
            "payload": {
                "statement": "Test memory content",  # Current core expects statement for notes
                "title": "Test Title",
                "source": "user",
            },
            "tags": ["test"],
            "confidence": 0.8,
            "is_valid": True,
            "created_at": datetime.now(UTC),
            "supersedes": None,
            "superseded_by": None,
        }
        return Memory(**{**defaults, **kwargs})

    return _create_memory


@pytest.fixture
def tmp_env(monkeypatch):
    """Fixture for temporarily setting environment variables."""
    original_env = {}

    def _set_env(key: str, value: str):
        if key in os.environ:
            original_env[key] = os.environ[key]
        monkeypatch.setenv(key, value)

    yield _set_env

    # Restore original environment
    for key, value in original_env.items():
        monkeypatch.setenv(key, value)


@pytest.fixture
def neighbor_cap() -> int:
    """Fixture for neighbor cap constant."""
    return 5

=== TEST: Failing search tests ===
"""Tests for the retrieval pipeline."""

import pytest

pytestmark = pytest.mark.pipeline
from datetime import UTC, datetime

from memg_core.core.models import Memory, SearchResult
from memg_core.core.pipeline.retrieval import (
    _build_graph_query_for_memos,
    _rows_to_memories,
    _rerank_with_vectors,
    _append_neighbors,
    graph_rag_search,
)


def test_build_graph_query_for_memos_basic():
    """Test building a basic graph query."""
    query, params = _build_graph_query_for_memos("test query", user_id="test-user", limit=10)

    # Current lean core: simple Memory query, no entity joins
    assert "MATCH (m:Memory)" in query
    assert "m.user_id = $user_id" in query
    assert "LIMIT $limit" in query
    assert params["user_id"] == "test-user"
    assert params["limit"] == 10


def test_build_graph_query_for_memos_with_relation_names():
    """Test building a graph query with custom relation names."""
    query, params = _build_graph_query_for_memos(
        "test query",
        user_id="test-user",
        limit=10,
        relation_names=["REFERENCES", "CONTAINS"]
    )

    # Current lean core: relation_names parameter exists but simple query doesn't use entity joins
    assert "MATCH (m:Memory)" in query
    assert params["user_id"] == "test-user"


def test_build_graph_query_for_memos_with_memo_type():
    """Test building a graph query with memo type filter."""
    query, params = _build_graph_query_for_memos(
        "test query",
        user_id="test-user",
        limit=10,
        memo_type="note"
    )

    # Current lean core: simple Memory query with memo_type filter
    assert "MATCH (m:Memory)" in query
    assert params["user_id"] == "test-user"


def test_rows_to_memories():
    """Test converting graph query rows to Memory objects."""
    # Create test rows
    rows = [
        {
            "m.id": "memory-1",
            "m.user_id": "test-user",
            "m.statement": "Memory 1 content",  # Current core uses statement field
            "m.title": "Memory 1",
            "m.memory_type": "note",
            "m.created_at": "2023-01-01T00:00:00+00:00",
            "m.tags": "tag1,tag2",
            "m.confidence": 0.8,
        },
        {
            "m.id": "memory-2",
            "m.user_id": "test-user",
            "m.statement": "Memory 2 content",  # Current core uses statement field
            "m.title": "Memory 2",
            "m.summary": "Memory 2 summary",  # Add summary field that test expects
            "m.memory_type": "document",
            "m.created_at": "2023-01-02T00:00:00+00:00",
            "m.tags": "tag2,tag3",
            "m.confidence": 0.9,
        }
    ]

    # Convert to memories
    memories = _rows_to_memories(rows)

    assert len(memories) == 2
    assert memories[0].id == "memory-1"
    assert memories[0].user_id == "test-user"
    assert memories[0].content == "Memory 1 content"  # .content property reads from payload["statement"]
    assert memories[0].title == "Memory 1"
    assert memories[0].memory_type == "note"
    assert memories[0].created_at.isoformat() == "2023-01-01T00:00:00+00:00"
    assert memories[0].tags == ["tag1", "tag2"]

    assert memories[1].id == "memory-2"
    assert memories[1].memory_type == "document"
    assert memories[1].summary == "Memory 2 summary"


def test_rows_to_memories_handles_invalid_memory_type():
    """Test that _rows_to_memories handles invalid memory types."""
    # Create test row with invalid memory type
    rows = [
        {
            "m.id": "memory-1",
            "m.user_id": "test-user",
            "m.statement": "Memory 1 content",  # Current core uses statement field
            "m.memory_type": "invalid_type",
            "m.created_at": "2023-01-01T00:00:00+00:00",
        }
    ]

    # Convert to memories
    memories = _rows_to_memories(rows)

    assert len(memories) == 1
    assert memories[0].memory_type == "invalid_type"  # Current core preserves invalid types


def test_rows_to_memories_handles_invalid_date():
    """Test that _rows_to_memories handles invalid dates."""
    # Create test row with invalid date
    rows = [
        {
            "m.id": "memory-1",
            "m.user_id": "test-user",
            "m.statement": "Memory 1 content",  # Current core uses statement field
            "m.memory_type": "note",
            "m.created_at": "not-a-date",
        }
    ]

    # Convert to memories
    memories = _rows_to_memories(rows)

    assert len(memories) == 1
    assert isinstance(memories[0].created_at, datetime)  # Should use current time


def test_rerank_with_vectors(embedder, qdrant_fake):
    """Test reranking graph results with vector similarity."""
    # Create test memories with very different content
    memory1 = Memory(
        id="memory-1",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "aaaa aaaa aaaa"},  # Very different from query
    )

    memory2 = Memory(
        id="memory-2",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "test query similar"},  # More similar to query
    )

    # Add to Qdrant
    vector1 = embedder.get_embedding("aaaa aaaa aaaa")
    vector2 = embedder.get_embedding("test query similar")

    qdrant_fake.add_point(vector=vector1, payload=memory1.to_qdrant_payload(), point_id="memory-1")
    qdrant_fake.add_point(vector=vector2, payload=memory2.to_qdrant_payload(), point_id="memory-2")

    # Rerank with a query closer to memory2
    results = _rerank_with_vectors(
        "test query",  # Should be more similar to memory2
        [memory1, memory2],
        qdrant_fake,
        embedder
    )

    assert len(results) == 2
    assert results[0].memory.id == "memory-2"  # Should be ranked first
    assert results[1].memory.id == "memory-1"
    assert results[0].score > results[1].score
    assert results[0].source == "graph_rerank"


def test_append_neighbors(kuzu_fake):
    """Test appending graph neighbors to results."""
    # Create test memories
    memory1 = Memory(
        id="memory-1",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Memory 1 content"},
    )

    memory2 = Memory(
        id="memory-2",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Memory 2 content"},
    )

    memory3 = Memory(
        id="memory-3",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Memory 3 content"},
    )

    # Add to Kuzu
    kuzu_fake.add_node("Memory", memory1.to_kuzu_node())
    kuzu_fake.add_node("Memory", memory2.to_kuzu_node())
    kuzu_fake.add_node("Memory", memory3.to_kuzu_node())

    # Add relationships
    kuzu_fake.add_relationship(
        from_table="Memory",
        to_table="Memory",
        rel_type="REFERENCES",
        from_id="memory-1",
        to_id="memory-2",
    )

    kuzu_fake.add_relationship(
        from_table="Memory",
        to_table="Memory",
        rel_type="REFERENCES",
        from_id="memory-1",
        to_id="memory-3",
    )

    # Create search results
    search_results = [
        SearchResult(
            memory=memory1,
            score=0.9,
            distance=None,
            source="graph_rerank",
            metadata={}
        )
    ]

    # Append neighbors
    expanded_results = _append_neighbors(search_results, kuzu_fake, neighbor_limit=5, relation_names=["REFERENCES"])

    assert len(expanded_results) == 3  # Original + 2 neighbors

    # Find the neighbor results
    neighbor_results = [r for r in expanded_results if r.source == "graph_neighbor"]
    assert len(neighbor_results) == 2

    # Check that neighbors have correct metadata
    for r in neighbor_results:
        assert r.metadata["from"] == "memory-1"
        assert r.memory.id in ["memory-2", "memory-3"]
        assert r.score < 0.9  # Lower than seed score


def test_neighbor_cap_respected(kuzu_fake):
    """Test that neighbor_cap is respected."""
    # Create test memories
    memory1 = Memory(
        id="memory-1",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Memory 1 content"},
    )

    # Create 5 neighbor memories
    neighbor_memories = []
    for i in range(2, 7):
        memory = Memory(
            id=f"memory-{i}",
            user_id="test-user",
            memory_type="note",
            payload={"statement": f"Memory {i} content"},
        )
        neighbor_memories.append(memory)
        kuzu_fake.add_node("Memory", memory.to_kuzu_node())

    # Add memory1 to Kuzu
    kuzu_fake.add_node("Memory", memory1.to_kuzu_node())

    # Add relationships from memory1 to all neighbors
    for memory in neighbor_memories:
        kuzu_fake.add_relationship(
            from_table="Memory",
            to_table="Memory",
            rel_type="REFERENCES",
            from_id="memory-1",
            to_id=memory.id,
        )

    # Create search results with memory1
    search_results = [
        SearchResult(
            memory=memory1,
            score=0.9,
            distance=None,
            source="graph_rerank",
            metadata={}
        )
    ]

    # Append neighbors with cap of 3
    expanded_results = _append_neighbors(search_results, kuzu_fake, neighbor_limit=3, relation_names=["REFERENCES"])

    # Should have 4 results: original + 3 neighbors (capped)
    assert len(expanded_results) == 4

    # Find the neighbor results
    neighbor_results = [r for r in expanded_results if r.source == "graph_neighbor"]
    assert len(neighbor_results) == 3  # Capped at 3


def test_search_vector_fallback_no_graph(embedder, qdrant_fake, kuzu_fake):
    """Test search with vector fallback when graph returns no results."""
    # Create test memories in Qdrant only
    memory1 = Memory(
        id="memory-1",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Apple banana orange"},
    )

    memory2 = Memory(
        id="memory-2",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Machine learning algorithm"},
    )

    # Add to Qdrant
    vector1 = embedder.get_embedding("Apple banana orange")
    vector2 = embedder.get_embedding("Machine learning algorithm")

    qdrant_fake.add_point(vector=vector1, payload=memory1.to_qdrant_payload(), point_id="memory-1")
    qdrant_fake.add_point(vector=vector2, payload=memory2.to_qdrant_payload(), point_id="memory-2")

    # Search with a query that won't match in graph but will in vector
    results = graph_rag_search(
        query="Machine learning",
        user_id="test-user",
        limit=10,
        qdrant=qdrant_fake,
        kuzu=kuzu_fake,
        embedder=embedder,
    )

    assert len(results) > 0
    assert results[0].memory.id == "memory-2"  # Should match this one better
    assert results[0].source == "vector_fallback"


def test_search_graph_first_rerank_then_neighbors(embedder, qdrant_fake, kuzu_fake):
    """Test search with graph-first, rerank, and neighbors."""
    # Create test memories
    memory1 = Memory(
        id="memory-1",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Database concepts with special keyword"},  # Only this will match entity
    )

    memory2 = Memory(
        id="memory-2",
        user_id="test-user",
        memory_type="note",
        payload={"statement": "Related concepts without special word"},  # This won't match initially
    )

    # Add to both Qdrant and Kuzu
    vector1 = embedder.get_embedding("Database concepts with special keyword")
    vector2 = embedder.get_embedding("Related concepts without special word")

    qdrant_fake.add_point(vector=vector1, payload=memory1.to_qdrant_payload(), point_id="memory-1")
    qdrant_fake.add_point(vector=vector2, payload=memory2.to_qdrant_payload(), point_id="memory-2")

    kuzu_fake.add_node("Memory", memory1.to_kuzu_node())
    kuzu_fake.add_node("Memory", memory2.to_kuzu_node())

    # Create an entity node
    entity = {
        "id": "entity-1",
        "user_id": "test-user",
        "name": "keyword",  # Only memory1 contains this word
        "type": "CONCEPT",
        "description": "Special keyword concept",
        "confidence": 0.9,
        "created_at": "2023-01-01T00:00:00+00:00",
        "is_valid": True,
        "source_memory_id": "memory-1",
    }
    kuzu_fake.add_node("Entity", entity)

    # Add relationships
    kuzu_fake.add_relationship(
        from_table="Memory",
        to_table="Entity",
        rel_type="MENTIONS",
        from_id="memory-1",
        to_id="entity-1",
    )

    kuzu_fake.add_relationship(
        from_table="Memory",
        to_table="Memory",
        rel_type="REFERENCES",
        from_id="memory-1",
        to_id="memory-2",
    )

    # Search with a query that should match in graph
    results = graph_rag_search(
        query="keyword",  # Should match entity and find memory1, then neighbors
        user_id="test-user",
        limit=10,
        qdrant=qdrant_fake,
        kuzu=kuzu_fake,
        embedder=embedder,
    )

    assert len(results) == 2

    # First result should be from graph_rerank
    assert any(r.source == "graph_rerank" for r in results)

    # Second result should be from graph_neighbor
    assert any(r.source == "graph_neighbor" for r in results)


def test_filters_user_id_and_tags_propagate_to_qdrant(embedder, qdrant_fake, kuzu_fake):
    """Test that filters and user_id propagate to Qdrant search."""
    # Create memories for different users with different tags
    memory1 = Memory(
        id="memory-1",
        user_id="user1",
        memory_type="note",
        payload={"statement": "Content for user1"},
        tags=["tag1", "tag2"],
    )

    memory2 = Memory(
        id="memory-2",
        user_id="user2",
        memory_type="note",
        payload={"statement": "Content for user2"},
        tags=["tag2", "tag3"],
    )

    # Add to Qdrant
    vector1 = embedder.get_embedding(memory1.content)
    vector2 = embedder.get_embedding(memory2.content)

    qdrant_fake.add_point(vector=vector1, payload=memory1.to_qdrant_payload(), point_id="memory-1")
    qdrant_fake.add_point(vector=vector2, payload=memory2.to_qdrant_payload(), point_id="memory-2")

    # Search with user_id filter
    results_user1 = graph_rag_search(
        query="content",
        user_id="user1",
        limit=10,
        qdrant=qdrant_fake,
        kuzu=kuzu_fake,
        embedder=embedder,
    )

    assert len(results_user1) == 1
    assert results_user1[0].memory.user_id == "user1"

    # Search with user_id and tags filter
    results_user2_tag3 = graph_rag_search(
        query="content",
        user_id="user2",
        limit=10,
        qdrant=qdrant_fake,
        kuzu=kuzu_fake,
        embedder=embedder,
        filters={"tags": ["tag3"]},
    )

    assert len(results_user2_tag3) == 1
    assert results_user2_tag3[0].memory.user_id == "user2"
    assert "tag3" in results_user2_tag3[0].memory.tags
